{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\log p(x) &= \\log \\int_z dz q(z | x) \\frac{p(x|z) p(z)}{q(x|z)} \\\\\n",
    "&\\ge \\int_z dz q(z | x) \\log  \\frac{p(x|z) p(z)}{q(x|z)} \\\\\n",
    "&= \\mathbb{E}_{Z \\sim q(z|x)} [\\log p(x|Z)] - \\mathbf{D}_{KL} (q(Z|x) || p(Z))\n",
    "\\end{align}\n",
    "\n",
    "학습 데이타를 잘 반영한다는 것은 maximum likelihood 처리와 비슷하게 $\\prod_{x \\in D} p(x)$를 최대화 하는 확률밀도함수 p(x)를 찾는 것이다. $\\log$를 취하면, $\\mathbb{E}_{X \\sim D} \\log p(X)$로 쓸 수 있다. 우변의 첫 항은 decoder에서 두번 째 항은 encoder와 관련되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 784])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    partial(torch.reshape, shape=(-1,)),\n",
    "])\n",
    "\n",
    "# Training dataset\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=img_transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "# Test dataset\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=False,\n",
    "        transform=img_transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "# sample plot\n",
    "for imgs, targets in train_loader:\n",
    "    print(imgs.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc11): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (mu): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (log_var): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (fc21): Linear(in_features=2, out_features=512, bias=True)\n",
       "  (fc22): Linear(in_features=512, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, nx, nh, nz):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.nz = nz\n",
    "        \n",
    "        # encoder\n",
    "        self.fc11 = nn.Linear(nx, nh)\n",
    "        self.mu = nn.Linear(nh, nz)\n",
    "        self.log_var = nn.Linear(nh, nz)\n",
    "        \n",
    "        # decoder\n",
    "        self.fc21 = nn.Linear(nz, nh)\n",
    "        self.fc22 = nn.Linear(nh, nx)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h = F.relu(self.fc11(x))\n",
    "        return self.mu(h), self.log_var(h)\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc21(z))\n",
    "        return F.sigmoid(self.fc22(h))\n",
    "    \n",
    "    def sample_z(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x)\n",
    "        z = self.sample_z(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n",
    "    \n",
    "vae = VAE(nx=784, nh=512, nz=2)\n",
    "vae.to(device)\n",
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "1. D. Carl, Tutorial on variational autoencoders, arXiv:1606.05908v2, 2016\n",
    "2. R.G. Krishnan, U. Shalit, D. Sontag, Deep Kalman Filters, arXiv:1511.05121v2, 2015\n",
    "3. J. Duchi, [Derivations for linear algebra and optimization](http://web.stanford.edu/~jduchi/projects/general_notes.pdf)\n",
    "4. A. Kristladl, [Variational autoencoder: intuition and implementation](https://wiseodd.github.io/techblog/2016/12/10/variational-autoencoder/), blog post 2016\n",
    "5. https://github.com/lyeoni/pytorch-mnist-VAE\n",
    "6. [mxnet variational autoencoder example](https://github.com/apache/incubator-mxnet/tree/master/example/autoencoder/variational_autoencoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
